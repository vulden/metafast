{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IT Валидация "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./sbe_valib/src/\")\n",
    "from sbe_vallib import validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://token:****@sberosc.ca.sbrf.ru/repo/pypi/simple\n",
      "Requirement already satisfied: feature-engine in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (1.6.2)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from feature-engine) (0.14.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from feature-engine) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from feature-engine) (1.3.2)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from feature-engine) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from feature-engine) (1.24.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from pandas>=1.0.3->feature-engine) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from pandas>=1.0.3->feature-engine) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from pandas>=1.0.3->feature-engine) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->feature-engine) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->feature-engine) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from statsmodels>=0.11.1->feature-engine) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from statsmodels>=0.11.1->feature-engine) (24.1)\n",
      "Requirement already satisfied: six in /data/yarn/workspace/21903373_omega-sbrf-ru/.local/lib/python3.8/site-packages (from patsy>=0.5.4->statsmodels>=0.11.1->feature-engine) (1.16.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --user feature-engine --index-url http://token:$'3c45e29ab890842649c7d351cda05a689c45682c'@sberosc.ca.sbrf.ru/repo/pypi/simple --trusted-host sberosc.ca.sbrf.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T12:40:14.583106Z",
     "start_time": "2023-12-11T12:39:25.729829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# папка с модулями\n",
    "homePath = os.getcwd()[0:os.getcwd().find('notebooks')]\n",
    "sys.path.insert(0, '/data/workspace/modules')\n",
    "sys.path.insert(0, homePath + 'pack_for_ldfunclib/python3.6')\n",
    "sys.path.insert(0, homePath + 'notebooks/ldfunclib')\n",
    "sys.path.insert(0, homePath + 'notebooks/modules')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import pickle\n",
    "\n",
    "import subprocess\n",
    "from catboost import Pool, CatBoostClassifier, cv\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sbe_vallib.sampler.supervised_sampler import SupervisedSampler \n",
    "from sbe_vallib.scorer.table_scorer import TableBinaryScorer\n",
    "from sbe_vallib.utils.metrics import BINARY_METRICS\n",
    "from sbe_vallib import Validation\n",
    "from sbe_vallib.table.data_quality.test_trend_corr import test_trend_corr, calculate_trend_corr, get_continuous_col, corr_trend_for_col\n",
    "from sbe_vallib.table.data_quality.test_psi_factor import test_psi_factor\n",
    "from sbe_vallib.table.specification.test_factor_correlation import test_factor_correlation\n",
    "from sbe_vallib.table.data_quality.test_extremal_missing_values import test_extremal_missing_values\n",
    "from sbe_vallib.table.data_quality.test_train_test_indepedence import calculate_indepedence_statistics, test_train_indepedence, create_data_for_gini, calculate_gini_random_list, plot_indepedence_hist_dist, calculate_cv_gini\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score, recall_score, precision_score, average_precision_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict, GroupKFold, KFold, train_test_split, StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import random\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sbe_vallib.sampler.supervised_sampler import SupervisedSampler \n",
    "from sbe_vallib.scorer.table_scorer import TableBinaryScorer\n",
    "from sbe_vallib.utils.metrics import BINARY_METRICS\n",
    "from sbe_vallib import Validation\n",
    "#subprocess.run('echo '+'пароль'+' | kinit '+ 'логин',shell=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### PERMUTATION IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_permutation_importance(X_train, y_train, X_test, y_test, features, clf=None, \n",
    "                                           params=None, n_jobs=1, seed=42, round_turn=5):\n",
    "    '''\n",
    "    Получаем importance фичей на основе пермутаций.\n",
    "    Вычисления важности фичей на основе пермутаций происходит при помощи\n",
    "    стандартной функции из sklearn: permutation_importance.\n",
    "    \n",
    "    Возвращает словарь вида {название фичи: importance фичи}\n",
    "    '''\n",
    "\n",
    "    model = clf(**params)\n",
    "    model.fit(X_train[features], y_train)\n",
    "    \n",
    "    # if n_jobs != 1:\n",
    "    np.random.seed(seed)\n",
    "    result = permutation_importance(\n",
    "                                    model, \n",
    "                                    X_test[features], \n",
    "                                    y_test, \n",
    "                                    n_repeats = 1, \n",
    "                                    n_jobs= n_jobs, \n",
    "                                    scoring=None, \n",
    "                                    random_state=seed\n",
    "                                   )\n",
    "    gc.collect()\n",
    "    \n",
    "    features_np = np.array(features)\n",
    "    \n",
    "    dct_permutation_score = dict(zip(features_np, \n",
    "                                     result.importances_mean\n",
    "                                    )\n",
    "                                )\n",
    "    \n",
    "    dct_permutation_score = {key:[values] for key, values in dct_permutation_score.items()}\n",
    "    \n",
    "    del(model)\n",
    "    gc.collect()\n",
    "    \n",
    "    return dct_permutation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### CATEGORICAL ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Подготовка категориальных признаков: поиск и замена\n",
    "    пропусков на фиксированное значение, применение\n",
    "    LabelEncoder'a для перевода категорий в целочисленные\n",
    "    векторы.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    config: dict\n",
    "        Словарь с настройками запуска ядра.\n",
    "\n",
    "    fill_value: string, optional, default = \"NA\"\n",
    "        Значение для заполнения пропущенных элементов.\n",
    "\n",
    "    copy: bool, optional, default = True\n",
    "        Если True, то создается копия data. Если False,\n",
    "        то все преобразования data производится inplace.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    _unique_values: Dict[string: list]\n",
    "        Словарь уникальных значений признака, для которых\n",
    "        был применен метод fit. Ключ словаря - название\n",
    "        категориального признака, значение - список уникальных\n",
    "        значений данного признака.\n",
    "\n",
    "    encoders: Dict[string: LabelEncoder()]\n",
    "        Словарь encoder'ов для каждого категориального признака.\n",
    "        Ключ словаря - название категориального признака,\n",
    "        значение - экземпляр LabelEncoder(), для которого\n",
    "        был применен метод fit.\n",
    "\n",
    "    cat_features: List[str]\n",
    "        Словарь строк с названием категориальных переменных.\n",
    "\n",
    "    fitted: bool\n",
    "        Флаг, обученного трансформера.\n",
    "        По умолчанию, равен False, т.е. обучение проведено не было.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 # config: dict,\n",
    "                 cat_features,\n",
    "                 fill_value: str = \"missing\",\n",
    "                 copy: bool = True) -> None:\n",
    "        self.fill_value = fill_value\n",
    "        # self.config = config\n",
    "        self.copy = copy\n",
    "\n",
    "        self.encoders = {}\n",
    "        self._unique_values = {}\n",
    "        self.cat_features = cat_features\n",
    "        self.fitted = False\n",
    "\n",
    "    def _copy(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        return data.copy() if self.copy else data\n",
    "\n",
    "    @property\n",
    "    def check_is_fitted(self):\n",
    "        \"\"\"\n",
    "        Свойство для проверки использования метода 'fit'.\n",
    "        Требуется для корректного применения трансформера на\n",
    "        тестовую / валидационную выборку. Если метод 'fit' не был\n",
    "        предварительно применен, то возбуждается исключение NotFittedError.\n",
    "\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            msg = (\"This estimator is not fitted yet. Call 'fit' with \"\n",
    "                   \"appropriate arguments before using this estimator.\")\n",
    "            raise NotFittedError(msg)\n",
    "        return True\n",
    "\n",
    "    def _prepare_data_dtypes(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Подготовка данных для передачи данных на вход encoder'a:\n",
    "            - замена пропусков на fill_value;\n",
    "            - преобразованеи столбца значений в object-столбец.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        series: pandas.Series\n",
    "            Вектор наблюдений.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        series_prepared: pandas.Series\n",
    "            Преобразованный вектор наблюдений.\n",
    "        \"\"\"\n",
    "        series_prepared = series.fillna(self.fill_value)\n",
    "        series_prepared = series_prepared.astype(\"str\")\n",
    "        return series_prepared\n",
    "\n",
    "    def _find_new_values(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Поиск новых значений категориального признака, которые\n",
    "        не были обработаны методом fit. Новые значения категории\n",
    "        заменяются на fill_value, если fill_value был обработан\n",
    "        методом fit, иначе - заменяются на первую обработанную\n",
    "        категорию.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        series: pandas.Series\n",
    "            Вектор наблюдений.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        series: pandas.Series\n",
    "            Преобразованный вектор наблюдений.\n",
    "        \"\"\"\n",
    "        observed_values = np.unique(series)\n",
    "        expected_values = self._unique_values[series.name]\n",
    "        new_values = list(set(observed_values) - set(expected_values))\n",
    "\n",
    "        if new_values:\n",
    "            bad_values_mask = (series.isin(new_values))\n",
    "            series[bad_values_mask] = self.fill_value if self.fill_value in \\\n",
    "                expected_values else expected_values[0]\n",
    "\n",
    "        return series\n",
    "\n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Обучение LabelEncoder'a\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data: pandas.DataFrame\n",
    "            Матрица признаков.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        self: CategoricalFeaturesTransformer\n",
    "        \"\"\"\n",
    "        # self.cat_features = find_categorical_features(\n",
    "        #     data, config=self.config)\n",
    "\n",
    "        for feature in self.cat_features:\n",
    "            x_prepared = self._prepare_data_dtypes(data[feature])\n",
    "            self._unique_values[feature] = np.unique(x_prepared).tolist()\n",
    "            self.encoders[feature] = LabelEncoder().fit(x_prepared)\n",
    "\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Преобразование data, используя LabelEncoder.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data: pandas.DataFrame\n",
    "            Матрица признаков.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        data_transformed: pandas.DataFrame\n",
    "            Преобразованная матрица признаков.\n",
    "        \"\"\"\n",
    "        self.check_is_fitted\n",
    "        x_transformed = self._copy(data)\n",
    "        encoded_features = list(set(self.cat_features) & set(data.columns))\n",
    "\n",
    "        for feature in encoded_features:\n",
    "            x_grouped = self._prepare_data_dtypes(x_transformed[feature])\n",
    "            x_grouped = self._find_new_values(x_grouped)\n",
    "\n",
    "            encoder = self.encoders[feature]\n",
    "            x_transformed[feature] = encoder.transform(x_grouped)\n",
    "\n",
    "        return x_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### PSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "class PSI(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Вычисление PSI и отбор признаков на их основе.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold: float\n",
    "        Порог для отбора переменных по PSI.\n",
    "        Если PSI для переменной выше порога - переменная макрируется\n",
    "        0 (не использовать для дальнейшего анализа), если ниже\n",
    "        порога - маркируется 1 (использовать для дальнейшего анализа).\n",
    "\n",
    "    n_bins: int, optional, default = 20\n",
    "        Количество бинов, на которые разбивается выборка.\n",
    "\n",
    "    min_value: float, optional, default = 0.005\n",
    "        Значение которое используется, если рассчитанный psi = 0.\n",
    "\n",
    "    bin_type: string, optional, default = \"quanitles\"\n",
    "        Способ разбиения на бины: \"quantiles\", \"bins\" or \"continuous\".\n",
    "        При выборе \"quantiles\" - выборка будет разбита на n_bins\n",
    "        квантилей, при выборке \"bins\" - выборка будет разбита на\n",
    "        n_bins бакетов с равным шагом между бакетами,\n",
    "        при выборе \"continuous\" - выборка будет разбита на бакеты с одинаковыми границами для двух выборок (train/test\n",
    "        или test/oot), где в каждом бакете не меннее определенной доли выборки (по умолчанию 5%).\n",
    "        Иные значения приводят к возникновению ValueError.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    scores_: Dict[str, float]\n",
    "        Словарь со значениями PSI,\n",
    "        ключ словаря - название признака, значение - PSI-score.\n",
    "\n",
    "    used_features: List[str]\n",
    "        Список отобранных признаокв.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 threshold: float,\n",
    "                 categorical_features: Optional[List[str]] = None,\n",
    "                 bin_type: str = \"quantiles\",\n",
    "                 min_value: float = 0.005,\n",
    "                 n_bins: int = 20):\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.categorical_features = categorical_features\n",
    "        self.min_value = min_value\n",
    "        self.n_bins = n_bins\n",
    "        if bin_type in [\"quantiles\", \"bins\", \"continuous\"]:\n",
    "            self.bin_type = bin_type\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Incorrect bin_type value. Expected 'quantiles', 'bins' or 'continuous', \"\n",
    "                f\"but {bin_type} is transferred.\"\n",
    "            )\n",
    "        self.scores = {}\n",
    "        self.used_features = None\n",
    "\n",
    "    @property\n",
    "    def check_is_fitted(self):\n",
    "        if not self.scores:\n",
    "            msg = (\"This estimator is not fitted yet. Call 'fit' with \"\n",
    "                   \"appropriate arguments before using this estimator.\")\n",
    "            raise NotFittedError(msg)\n",
    "        return True\n",
    "\n",
    "    def calculate_bins(self, expected: pd.Series, actual: pd.Series, threshold: float = 0.05) -> np.array:\n",
    "        \"\"\"\n",
    "        Вычисление границ бинов для разбиения выборки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expected: pandas.Series, shape = [n_samples_e, ]\n",
    "            Наблюдения из train-выборки.\n",
    "\n",
    "        actual: pandas.Series, shape = [n_samples_o, ]\n",
    "            Наблюдения из test-выборки.\n",
    "            (требуется для разбиения по тактике \"continuous\")\n",
    "\n",
    "        threshold: float\n",
    "            Минимальная доля выборки в бакете.\n",
    "            (требуется для разбиения по тактике \"continuous\")\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bins: numpy.array, shape = [self.n_bins + 1]\n",
    "            Список с границами бинов.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.bin_type == \"quantiles\":\n",
    "            bins = np.linspace(0, 100, self.n_bins + 1)\n",
    "            bins = [np.nanpercentile(expected, x) for x in bins]\n",
    "        elif self.bin_type == \"continuous\":\n",
    "            min_expected_len = int(len(expected) * threshold)\n",
    "            min_actual_len = int(len(actual) * threshold)\n",
    "            bins = sorted(self.calculate_continuous_bins(expected, actual, min_expected_len, min_actual_len))\n",
    "        else:\n",
    "            bins = np.linspace(expected.min(), expected.max(), self.n_bins + 1)\n",
    "\n",
    "        return np.unique(bins)\n",
    "\n",
    "    def calculate_continuous_bins(self, expected: pd.Series, actual: pd.Series,\n",
    "                                  min_expected_len: int, min_actual_len: int, result: List = None):\n",
    "        \"\"\"\n",
    "        Вычисление границ бинов по тактике \"continuous\". Выборка будет разбита на бакеты с одинаковыми границами\n",
    "        для двух выборок expected/actual (train/test или test/oot),\n",
    "        где в каждом бакете не меннее определенной доли выборки (по умолчанию 5%).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expected: pandas.Series, shape = [n_samples_e, ]\n",
    "            Наблюдения из train-выборки.\n",
    "\n",
    "        actual: pandas.Series, shape = [n_samples_o, ]\n",
    "            Наблюдения из test-выборки.\n",
    "\n",
    "        min_expected_len: int\n",
    "            Минимальное количество значений в бакете для выборки expected.\n",
    "\n",
    "        min_actual_len: int\n",
    "            Минимальное количество значений в бакете для выборки actual.\n",
    "\n",
    "        result: List\n",
    "            Переменная для хранения результатов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        result: List\n",
    "            Список с границами бинов.\n",
    "\n",
    "        \"\"\"\n",
    "        if not result:\n",
    "            result = []\n",
    "\n",
    "        median_value = np.median(expected)\n",
    "\n",
    "        left_test = expected[expected <= median_value]\n",
    "        left_oot = actual[actual <= median_value]\n",
    "        right_test = expected[expected > median_value]\n",
    "        right_oot = actual[actual > median_value]\n",
    "        if len(left_test) >= min_expected_len and len(left_oot) >= min_actual_len and \\\n",
    "                len(right_test) >= min_expected_len and len(right_oot) >= min_actual_len:\n",
    "            if median_value not in result:\n",
    "                result.append(median_value)\n",
    "            result = self.calculate_continuous_bins(left_test, left_oot, min_expected_len, min_actual_len, result)\n",
    "            result = self.calculate_continuous_bins(right_test, right_oot, min_expected_len, min_actual_len, result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def calculate_psi_in_bin(self, expected_score, actual_score) -> float:\n",
    "        \"\"\"\n",
    "        Вычисление значения psi для одного бакета.\n",
    "\n",
    "        Осуществляется проверка на равенство нулю expected_score и\n",
    "        actual_score: если один из аргументов равен нулю, то его\n",
    "        значение заменяется на self.min_value.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expected_score: float\n",
    "            Ожидаемое значение.\n",
    "\n",
    "        actual_score: float\n",
    "            Наблюдаемое значение.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        value: float\n",
    "            Значение psi в бине.\n",
    "\n",
    "        \"\"\"\n",
    "        if expected_score == 0:\n",
    "            expected_score = self.min_value\n",
    "        if actual_score == 0:\n",
    "            actual_score = self.min_value\n",
    "\n",
    "        value = (expected_score - actual_score)\n",
    "        value = value * np.log(expected_score / actual_score)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def calculate_psi(self, expected: pd.Series, actual: pd.Series, bins) -> float:\n",
    "        \"\"\"\n",
    "        Расчет PSI для одной переменной.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expected: pandas.Series, shape = [n_samples_e, ]\n",
    "            Наблюдения из train-выборки.\n",
    "\n",
    "        actual: pandas.Series, shape = [n_samples_o, ]\n",
    "            Наблюдения из test-выборки.\n",
    "\n",
    "        bins: pandas.Series, shape = [self.n_bins, ]\n",
    "            Бины для расчета PSI.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        psi_score: float\n",
    "            PSI-значение для данной пары выборок.\n",
    "\n",
    "        \"\"\"\n",
    "        expected_score = np.histogram(expected.fillna(-9999), bins)[0]\n",
    "        expected_score = expected_score / expected.shape[0]\n",
    "\n",
    "        actual_score = np.histogram(actual.fillna(-9999), bins)[0]\n",
    "        actual_score = actual_score / actual.shape[0]\n",
    "\n",
    "        psi_score = np.sum(\n",
    "            self.calculate_psi_in_bin(exp_score, act_score)\n",
    "            for exp_score, act_score in zip(expected_score, actual_score)\n",
    "        )\n",
    "\n",
    "        return psi_score\n",
    "\n",
    "    def calculate_numeric_psi(self, expected: pd.Series, actual: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Вычисление PSI для числовой переменной.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expected: pandas.Series, shape = [n_samples_e, ]\n",
    "            Наблюдения из train-выборки.\n",
    "\n",
    "        actual: pandas.Series, shape = [n_samples_o, ]\n",
    "            Наблюдения из test-выборки.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        psi_score: float\n",
    "            PSI-значение для данной пары выборок.\n",
    "\n",
    "        \"\"\"\n",
    "        bins = self.calculate_bins(expected, actual)\n",
    "        psi_score = self.calculate_psi(expected, actual, bins)\n",
    "        return psi_score\n",
    "\n",
    "    def calculate_categorical_psi(self, expected: pd.Series, actual: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Вычисление PSI для категориальной переменной.\n",
    "        PSI рассчитывается для каждого уникального значения категории.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expected: pandas.Series, shape = [n_samples_e, ]\n",
    "            Наблюдения из train-выборки.\n",
    "\n",
    "        actual: pandas.Series, shape = [n_samples_o, ]\n",
    "            Наблюдения из test-выборки.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        psi_score: float\n",
    "            PSI-значение для данной пары выборок.\n",
    "\n",
    "        \"\"\"\n",
    "        bins = np.unique(expected).tolist()\n",
    "        expected_score = expected.value_counts(normalize=True)\n",
    "        actual_score = actual.value_counts(normalize=True)\n",
    "\n",
    "        expected_score = expected_score.sort_index().values\n",
    "        actual_score = actual_score.sort_index().values\n",
    "\n",
    "        psi_score = np.sum(\n",
    "            self.calculate_psi_in_bin(exp_score, act_score)\n",
    "            for exp_score, act_score in zip(expected_score, actual_score)\n",
    "        )\n",
    "        return psi_score\n",
    "\n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Вычисление PSI-значения для всех признаков.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pandas.DataFrame, shape = [n_samples, n_features]\n",
    "            Матрица признаков для обучения.\n",
    "\n",
    "        target: pandas.DataFrame, shape = [n_samples, n_features]\n",
    "            Матрица признаков для тестирования.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        missed_columns = list(set(data.columns) - set(target.columns))\n",
    "\n",
    "        if missed_columns:\n",
    "            raise MissedColumnError(\n",
    "                f\"Missed {list(missed_columns)} columns in data.\")\n",
    "\n",
    "        if self.categorical_features:\n",
    "            numeric_features = list(\n",
    "                set(data.columns) - set(self.categorical_features)\n",
    "            )\n",
    "            self.categorical_features = list(\n",
    "                set(data.columns) & set(self.categorical_features)\n",
    "            )\n",
    "            for feature in self.categorical_features:\n",
    "                self.scores[feature] = self.calculate_categorical_psi(\n",
    "                    data[feature], target[feature]\n",
    "                )\n",
    "        else:\n",
    "            numeric_features = data.columns\n",
    "\n",
    "        for feature in tqdm(numeric_features):\n",
    "            self.scores[feature] = self.calculate_numeric_psi(\n",
    "                data[feature], target[feature]\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def transform(self, data, target=None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Отбор переменных по self.threshold.\n",
    "        Если PSI-score для переменной выше порога, то переменная\n",
    "        помечается 0 (не использовать для дальнейшего анализа), если ниже\n",
    "        порога - маркируется 1 (использовать для дальнейшего анализа).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pandas.DataFrame, shape = [n_samples, n_features]\n",
    "            Матрица признаков для обучения.\n",
    "\n",
    "        target: pandas.DataFrame, shape = [n_samples, n_features]\n",
    "            Матрица признаков для тестирования.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scores: pandas.DataFrame, shape = [n_features, 3]\n",
    "            Датафрейм с PSI-анализом переменных.\n",
    "\n",
    "        \"\"\"\n",
    "        self.check_is_fitted\n",
    "        scores = pd.Series(self.scores)\n",
    "        scores = pd.DataFrame({\"Variable\": scores.index, \"PSI\": scores.values})\n",
    "        scores[\"Selected\"] = np.where(scores.PSI < self.threshold, 1, 0)\n",
    "        scores = scores.sort_values(by=\"PSI\")\n",
    "\n",
    "        mask = scores[\"Selected\"] == 1\n",
    "        self.used_features = scores.loc[mask, \"Variable\"].tolist()\n",
    "\n",
    "        return scores.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def choose_psi_sample(eval_sets: dict, config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Выбор выборки для расчета PSI.\n",
    "    Выбор осуществляется на основании параметра `psi_sample` в\n",
    "    конфигурационном файле эксперимента. Если значение равно\n",
    "    `valid` / `test` - то выбирается данная выборка целиком,\n",
    "    значение равно `OOT` - то выборка разбивается на 2\n",
    "    непересекающихся выборки, одна из которых используется\n",
    "    для расчета PSI, другая используется для независимой\n",
    "    оценки качества.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_sets: Dict[str, Tuple[pd.DataFrame, pd.Series]]\n",
    "        pass\n",
    "\n",
    "    config: dict\n",
    "        Словарь с конфигурацией эксперимента.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eval_sets: Dict[str, Tuple[pd.DataFrame, pd.Series]]\n",
    "        Преобразованный словарь с eval_set.\n",
    "\n",
    "    psi_sample: pd.DataFrame\n",
    "        Выборка для расчета PSI.\n",
    "\n",
    "    \"\"\"\n",
    "    psi_sample_name = config.get(\"psi_sample\", \"OOT\")\n",
    "\n",
    "    if psi_sample_name in [None, \"train\"]:\n",
    "        return eval_sets, eval_sets[\"train\"][0]\n",
    "\n",
    "    if psi_sample_name in [\"valid\", \"test\"]:\n",
    "        return eval_sets, eval_sets[psi_sample_name][0]\n",
    "\n",
    "    elif psi_sample_name == \"OOT\":\n",
    "        oot_evaluate, oot_psi = train_test_split(\n",
    "            eval_sets[\"OOT\"][0], train_size=0.5, random_state=1\n",
    "        )\n",
    "        oot_target_evaluate, oot_target_psi = train_test_split(\n",
    "            eval_sets[\"OOT\"][1], train_size=0.5, random_state=1\n",
    "        )\n",
    "        eval_sets[\"OOT\"] = (oot_evaluate, oot_target_evaluate)\n",
    "        eval_sets[\"OOT_psi\"] = (oot_psi, oot_target_psi)\n",
    "\n",
    "        return eval_sets, oot_psi\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown psi-sample name! Please choose: {eval_sets.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Lower numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[numeric_col_names] = df_train[numeric_col_names].apply(lower_numeric)\n",
    "numeric_col_names = df_train.select_dtypes(include='number').columns.tolist()\n",
    "categorical_col_names = df_train.select_dtypes(exclude='number').columns.tolist()\n",
    "\n",
    "def lower_numeric(x, include_uint=True, lowest_float_type=np.float32):\n",
    "    int_type_list_int = [\n",
    "        np.int8,\n",
    "        # np.uint8,\n",
    "        np.int16,\n",
    "        # np.uint16,\n",
    "        np.int32,\n",
    "        # np.uint32,\n",
    "        np.int64,\n",
    "        # np.uint64\n",
    "    ]\n",
    "    \n",
    "    int_type_list_int_uint = [\n",
    "        np.int8,\n",
    "        np.uint8,\n",
    "        np.int16,\n",
    "        np.uint16,\n",
    "        np.int32,\n",
    "        np.uint32,\n",
    "        np.int64,\n",
    "        np.uint64\n",
    "    ]\n",
    "    \n",
    "    float_type_list_short = [\n",
    "        np.float128,\n",
    "        np.float64,\n",
    "        np.float32,\n",
    "        np.float16\n",
    "    ]\n",
    "    \n",
    "    if include_uint:\n",
    "        int_type_list = int_type_list_int_uint\n",
    "    else:\n",
    "        int_type_list = int_type_list_int\n",
    "    \n",
    "    if x.dtype in float_type_list_short:\n",
    "        if all(x == x.astype(np.int64)):\n",
    "            x = x.astype(np.int64)\n",
    "\n",
    "        elif (x.max() > np.finfo(lowest_float_type).max) or (x.min() < np.finfo(lowest_float_type).min):\n",
    "            x = np.log(x - x.min() + 1)\n",
    "            x = x.astype(lowest_float_type)\n",
    "        else:\n",
    "            x = x.astype(lowest_float_type)\n",
    "    \n",
    "    if x.dtype in int_type_list:\n",
    "        for int_type in int_type_list:\n",
    "            if (x.min() >= np.iinfo(int_type).min) & (x.max() <= np.iinfo(int_type).max):\n",
    "                x = x.astype(int_type)\n",
    "                break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(model, train, tests):\n",
    "    model.fit(train[0], train[1])\n",
    "    for test in tests:\n",
    "        predictions_oot = model.predict(test[0])\n",
    "        predict_proba_oot = model.predict_proba(test[0])[:,1]\n",
    "        metric(test[1], predictions_oot, predict_proba_oot)\n",
    "\n",
    "# example\n",
    "check_model(clf, [train_cb, train_shuffled.target], [(oot_cb, oot['target']), (oos_cb, oos['target'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CATBOOST FEATURE IMPORTANCE VISUALISATION\n",
    "plt.rcdefaults()\n",
    "plt.figure(figsize=(15,6)) \n",
    "\n",
    "plt.subplot(121)\n",
    "sorted_feature_importance = clf_t.feature_importances_.argsort()\n",
    "plt.barh(selected_features[-20:], clf_t.feature_importances_[sorted_feature_importance][-20:])\n",
    "plt.title(\"Feature Importance. Top-20.\")\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, emb_dim = 64, hid_dim = 256, output_dim = 128, n_layers = 2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_features = num_features # 7 and 29 are categorical\n",
    "        self.emb = nn.Embedding(5000, emb_dim)\n",
    "        self.out = nn.Linear(output_dim, 2)\n",
    "        self.act = nn.ReLU()\n",
    "        all_layers = [nn.LazyLinear(hid_dim), nn.ReLU(inplace=True)]\n",
    "        for i in range(n_layers):\n",
    "            all_layers.append(nn.Linear(hid_dim, hid_dim))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(hid_dim))\n",
    "            all_layers.append(nn.Dropout(0.2))\n",
    "        all_layers.append(nn.Linear(hid_dim, 1))\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        sub = x[:,[7, 29]].to(dtype=torch.int32)\n",
    "        x = torch.cat((self.emb(sub).flatten(1), x), 1)\n",
    "        x = torch.sigmoid(self.layers(x))\n",
    "        return x.squeeze(1)\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "batch_size = 4096\n",
    "X, y = train_cb.values, train_shuffled.target.values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_train, y_train = torch.tensor(X_train, dtype = torch.float32), torch.tensor(y_train, dtype = torch.float32)\n",
    "X_val, y_val = torch.tensor(X_val, dtype = torch.float32), torch.tensor(y_val, dtype = torch.float32)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = MLP(X_train.shape[1], emb_dim=256, hid_dim = 1024, n_layers = 3)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "n_epochs = 25\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "roc_auc_hist = []\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "    scheduler.step() \n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_labels, test_probs = [], []\n",
    "        for inputs, labels in val_loader:\n",
    "            out = model(inputs)\n",
    "            test_probs.extend(out.numpy())\n",
    "            test_labels.extend(labels.numpy())\n",
    "        ROC_AUC = roc_auc_score(np.array(test_labels), np.array(test_probs))\n",
    "    print(f'Roc-auc score : {ROC_AUC}')\n",
    "    roc_auc_hist.append(ROC_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn_model(model, tests):\n",
    "    model.eval()\n",
    "    batch_size = 9192\n",
    "    with torch.no_grad():\n",
    "        for test in tests:\n",
    "            test_labels, test_probs = [], []\n",
    "            X_train, y_train = torch.tensor(test[0].values, dtype = torch.float32), torch.tensor(test[1].values, dtype = torch.float32)\n",
    "            test_set = TensorDataset(X_train, y_train)\n",
    "            test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "            for inputs, labels in test_loader:\n",
    "                out = model(inputs)\n",
    "                test_probs.extend(out.numpy())\n",
    "                test_labels.extend(labels.numpy())\n",
    "            ROC_AUC = roc_auc_score(np.array(test_labels), np.array(test_probs))\n",
    "        print(f'ROC_AUC : {ROC_AUC}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CATBOOST HYPERPARAMETERS TUNING USING VALIDATION\n",
    "# add feature\n",
    "selected_features_all_new = selected_features_all + [\"source\"]\n",
    "selected_features_cat_new = selected_features_cat + [\"source\"]\n",
    "train_pool = Pool(\n",
    "    data=train[selected_features_all_new],\n",
    "    label=train['target'],\n",
    "    cat_features=selected_features_cat_new,\n",
    "    group_id=train['inn'],\n",
    ")\n",
    "\n",
    "oos_pool = Pool(\n",
    "    data=oos[selected_features_all_new],\n",
    "    label=oos['target'],\n",
    "    cat_features=selected_features_cat_new,\n",
    "    group_id=oos['inn'],\n",
    ")\n",
    "\n",
    "oot_pool = Pool(\n",
    "    data=oot[selected_features_all_new],\n",
    "    label=oot['target'],\n",
    "    cat_features=selected_features_cat_new,\n",
    "    group_id=oot['inn'],\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# train/validation split by inn\n",
    "splitter = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state=42)\n",
    "split = splitter.split(train, groups=train.inn)\n",
    "train_core_inds, valid_inds = next(split)\n",
    "\n",
    "train_core = train.iloc[train_core_inds].copy()\n",
    "valid = train.iloc[valid_inds].copy()\n",
    "\n",
    "\n",
    "train_core_pool = Pool(\n",
    "    data=train_core[selected_features_all_new],\n",
    "    label=train_core['target'],\n",
    "    cat_features=selected_features_cat_new,\n",
    "    group_id=train_core['inn'],\n",
    ")\n",
    "\n",
    "valid_pool = Pool(\n",
    "    data=valid[selected_features_all_new],\n",
    "    label=valid['target'],\n",
    "    cat_features=selected_features_cat_new,\n",
    "    group_id=valid['inn'],\n",
    ")\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define parameters space\n",
    "    params = {\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': 42,\n",
    "        'iterations':  1500,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'grow_policy': 'SymmetricTree',\n",
    "\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.3),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 100),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 100),\n",
    "        'depth': trial.suggest_int('depth', 2, 10),\n",
    "        'rsm': trial.suggest_float('rsm', 0.3, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 2, 254),\n",
    "        'bootstrap_type':  trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "    }\n",
    "        \n",
    "    if params['bootstrap_type'] == \"Bayesian\":\n",
    "        params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif params['bootstrap_type'] == \"Bernoulli\":\n",
    "        params['subsample'] = trial.suggest_float('subsample', 0.3, 1)\n",
    "    \n",
    "    # Define groups cross-validation splitter\n",
    "    splitter = GroupKFold(n_splits=3)\n",
    "    \n",
    "    # Get cross-validation results\n",
    "    cv_data = cv(\n",
    "        params=params,\n",
    "        pool=train_pool,\n",
    "        logging_level='Silent',\n",
    "        folds=splitter,\n",
    "        early_stopping_rounds=50, \n",
    "        stratified=True\n",
    "    )\n",
    "\n",
    "    return cv_data['test-AUC-mean'].max()\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# train/validation split by inn\n",
    "splitter = GroupShuffleSplit(test_size=0.1, n_splits=1, random_state=42)\n",
    "split = splitter.split(train, groups=train.inn)\n",
    "train_core_inds, valid_inds = next(split)\n",
    "\n",
    "train_core = train.iloc[train_core_inds].copy()\n",
    "valid = train.iloc[valid_inds].copy()\n",
    "\n",
    "study = optuna.create_study(study_name='catboost_cv_tuning', \n",
    "                            direction='maximize', \n",
    "                            sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=4, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CATBOOST HYPERPARAMETERS TUNING CV\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits = 3, shuffle = True, random_state = SEED)\n",
    "best_booster = None\n",
    "cat_boost = None\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    global cat_boost\n",
    "    \n",
    "    model_param = {\n",
    "    \"depth\": trial.suggest_int(\"depth\", 2, 16, 1),  \n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1100, 200),   \n",
    "    \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.01, 0.05, 0.1, 0.5]),\n",
    "    \"l2_leaf_reg\": trial.suggest_categorical(\"l2_leaf_reg\", [0.01, 0.05, 0.1, 0.5, 1]),\n",
    "    \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1),\n",
    "    \"rsm\": trial.suggest_uniform(\"rsm\", 0.5, 1)\n",
    "    }\n",
    "\n",
    "    cat_boost = cb.CatBoostClassifier(**model_param, \n",
    "                                      random_state = SEED,  \n",
    "                                      loss_function = 'Logloss', \n",
    "                                      eval_metric = 'AUC', \n",
    "                                      thread_count = 25, \n",
    "                                      cat_features = ['vacancy_title', 'city'], \n",
    "                                      verbose = False\n",
    "                                     )\n",
    "    \n",
    "    ROC_AUC = cross_val_score(cat_boost, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()\n",
    "    \n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "        \n",
    "    return ROC_AUC\n",
    "\n",
    "\n",
    "\n",
    "# callback для сохранения лучшей модели\n",
    "def callback(study, trial):\n",
    "    global best_booster\n",
    "    if study.best_trial == trial:\n",
    "        best_booster = cat_boost\n",
    "        \n",
    "n_trials=100\n",
    "study_cat = optuna.create_study(direction=\"maximize\", sampler=TPESampler(seed=SEED), pruner=optuna.pruners.HyperbandPruner(\n",
    "                                                                                      min_resource=3, max_resource=n_trials, reduction_factor=3))\n",
    "study_cat.optimize(objective, n_trials=n_trials, show_progress_bar=True, callbacks=[callback])\n",
    "\n",
    "print(\"Number of finished trials: \", len(study_cat.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study_cat.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## CATBOOST FEATURE IMPORTANCE \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mrcdefaults()\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m6\u001b[39m)) \n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m121\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "## CATBOOST FEATURE IMPORTANCE \n",
    "plt.rcdefaults()\n",
    "plt.figure(figsize=(15,6)) \n",
    "\n",
    "plt.subplot(121)\n",
    "sorted_feature_importance = CatBoostclf_opt.feature_importances_.argsort()\n",
    "plt.barh(oos.columns[sorted_feature_importance][-20:], CatBoostclf.feature_importances_[sorted_feature_importance][-20:])\n",
    "plt.title(\"Feature Importance. Top-20.\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "## SHAP FOR CATBOOST\n",
    "explainer = shap.TreeExplainer(CatBoostclf_opt)\n",
    "shap_values = explainer.shap_values(oos)\n",
    "\n",
    "shap.summary_plot(shap_values, oos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DF PREPARATION FOR NN ##\n",
    "cb_enc = CatBoostEncoder(cols=list(set(final_features)-set([\"city\", \"vacancy_title\"])))\n",
    "train_shuffled = train.sample(frac=1)\n",
    "\n",
    "train_cb = cb_enc.fit_transform(train_shuffled.drop(columns=[\"target\"]), train_shuffled.target)\n",
    "oot_cb = cb_enc.transform(oot.drop(columns=[\"target\"]))\n",
    "oos_cb = cb_enc.transform(oos.drop(columns=[\"target\"]))\n",
    "\n",
    "ord_enc = OrdinalEncoder(cols=[\"city\", \"vacancy_title\"], handle_unknown=1)\n",
    "train_cb = ord_enc.fit_transform(train_cb)[final_features]\n",
    "oot_cb = ord_enc.transform(oot_cb)[final_features]\n",
    "oos_cb = ord_enc.transform(oos_cb)[final_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import check_scoring\n",
    "from sklearn.model_selection import check_cv, StratifiedKFold\n",
    "\n",
    "\n",
    "###############\n",
    "### EXAMPLE ###\n",
    "###############\n",
    "\n",
    "# rfecv = RFECV(estimator=lightgbm.LGBMClassifier(n_jobs=25),\n",
    "#               step=0,\n",
    "#               cv=cv_index,\n",
    "#               verbose=2,\n",
    "#               scoring='roc_auc')\n",
    "#\n",
    "# rfecv.fit(e.train[e.feats], e.train['churn_flag'])\n",
    "\n",
    "\n",
    "class RFECV:\n",
    "    \"\"\"\n",
    "    В отличие от sklearn и yellowbrick мой RFECV позволяет настраивать максимальное количество фичей\n",
    "    с помощью трешхолда на метрику.\n",
    "    Также в отличие от sklearn выдает стандартное отклонение, и в отличие от yellowbrick - считается быстрее\n",
    "    (есть и такая вероятность).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : str | callable\n",
    "        estimator object implementing 'fit'. The object to use to fit the data.\n",
    "    step : int\n",
    "        numbers of features to drop during each run. If '0' is selected, then custom non-linear function is used for number of steps\n",
    "    cv : callable\n",
    "    verbose : int\n",
    "    scoring : str | callable\n",
    "        scoring method as string or callable from make_scorer function\n",
    "    random_state : int\n",
    "    threshold : float\n",
    "    Returns\n",
    "    -------\n",
    "    scorer : callable\n",
    "        The scorer.\n",
    "    \"\"\"\n",
    "\n",
    "    n_features_ = 0\n",
    "    support_ = []\n",
    "    grid_train_scores_ = []\n",
    "    grid_test_scores_ = []\n",
    "    grid_train_sd_ = []\n",
    "    grid_test_sd_ = []\n",
    "\n",
    "    def __init__(self, estimator, step, cv=3, verbose=0, scoring=None, random_state=0, threshold=0, use_sd=True):\n",
    "\n",
    "        self.estimator = estimator\n",
    "        self.step = step\n",
    "        self.kf = StratifiedKFold(n_splits = cv) # check_cv(cv, classifier=True)\n",
    "        self.verbose = verbose\n",
    "        # для обратной совместимости\n",
    "        if scoring == 'roc_auc_score': scoring = 'roc_auc'\n",
    "        self.scorer = check_scoring(estimator, scoring)\n",
    "        self.threshold = threshold\n",
    "        self.use_sd = use_sd\n",
    "\n",
    "    def _check_step(self, X, step):\n",
    "\n",
    "        if (len(X.columns) < 20) and (step == 0):\n",
    "            raise ValueError(\n",
    "                \"Custom step function is not supported for datasets with less then 20 features. Palse choose step>0\")\n",
    "        else:\n",
    "            return step\n",
    "\n",
    "    def _threshold_select_best_step(self, threshold):\n",
    "\n",
    "        self.score = max(self.grid_test_scores_)\n",
    "        best_idx = self.grid_test_scores_.index(self.score)\n",
    "        score_threshold = self.score - threshold\n",
    "        if self.use_sd:\n",
    "            score_threshold -= 2 * self.grid_test_sd_[best_idx]\n",
    "\n",
    "        if best_idx != 0 and threshold > 0:\n",
    "            for i in range(best_idx):\n",
    "                if self.grid_test_scores_[i] - 2 * self.grid_test_sd_[i] >= score_threshold:\n",
    "                    self.score = self.grid_test_scores_[i]\n",
    "                    best_idx = i\n",
    "                    break\n",
    "\n",
    "        best_step = best_idx + 1\n",
    "        return best_step\n",
    "\n",
    "    def fit(self, X_train, y_train, **kwargs):\n",
    "\n",
    "        self.feature_stats_ = pd.DataFrame({\n",
    "            'names': X_train.columns.values,\n",
    "            'step': np.nan,\n",
    "            'train_scores': np.nan,\n",
    "            'test_scores': np.nan,\n",
    "            'train_sd': np.nan,\n",
    "            'test_sd': np.nan,\n",
    "        })\n",
    "        x_tr = X_train\n",
    "\n",
    "        estimator = self.estimator\n",
    "        step = self._check_step(X_train, self.step)\n",
    "        kf = self.kf\n",
    "        scorer = self.scorer\n",
    "        threshold = self.threshold\n",
    "        verbose = self.verbose\n",
    "\n",
    "        if 'importance_type' in estimator.get_params():\n",
    "            estimator.set_params(importance_type='gain')\n",
    "\n",
    "        if step == 0:\n",
    "            n_cuts = 20\n",
    "            coef = [x / (x + 1) for x in range(1, 11)]\n",
    "            n_qcut = [len(x_tr.columns.values) * x ** 20 for x in coef].index(\n",
    "                [y for y in [len(x_tr.columns.values) * x ** 20 for x in coef] if 1 < y < 10][0]\n",
    "            ) + 2\n",
    "            if len(x_tr.columns.values) < 150:\n",
    "                n_qcut += 1\n",
    "            if len(x_tr.columns.values) < 90:\n",
    "                n_qcut += 2\n",
    "        else:\n",
    "            n_cuts = int(len(x_tr.columns.values) / step)\n",
    "\n",
    "        for n in range(n_cuts, 0, -1):\n",
    "            if x_tr.shape[1] < 1:\n",
    "                break\n",
    "\n",
    "            if verbose >= 1:\n",
    "                print(f'Fitting estimator with {len(x_tr.columns.values)} features.', end=' ')\n",
    "\n",
    "            if step != 0 or n == 1:\n",
    "                n_qcut = n\n",
    "            elif x_tr.shape[1] == 1:\n",
    "                n_qcut = 1\n",
    "\n",
    "            estimator.fit(x_tr, y_train, **kwargs)\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'names': x_tr.columns.values,\n",
    "                'gain': estimator.feature_importances_,\n",
    "            })\n",
    "\n",
    "            feature_importance = feature_importance.sort_values(by=\"gain\", ascending=False)\n",
    "            feature_importance['step'] = pd.qcut(range(len(feature_importance)), n_qcut, labels=False) + 1\n",
    "\n",
    "            scores = cross_validate(\n",
    "                estimator,\n",
    "                x_tr,\n",
    "                y_train,\n",
    "                cv=kf,\n",
    "                scoring=scorer,\n",
    "                return_train_score=True,\n",
    "            )\n",
    "\n",
    "            self.grid_train_scores_ = [np.mean(scores['train_score'])] + self.grid_train_scores_\n",
    "            self.grid_test_scores_ = [np.mean(scores['test_score'])] + self.grid_test_scores_\n",
    "            self.grid_train_sd_ = [np.std(scores['train_score'])] + self.grid_train_sd_\n",
    "            self.grid_test_sd_ = [np.std(scores['test_score'])] + self.grid_test_sd_\n",
    "\n",
    "            to_drop_cols = feature_importance['names'][feature_importance['step'] == n_qcut].tolist()\n",
    "            x_tr = x_tr.drop(to_drop_cols, axis=1)\n",
    "            self.feature_stats_.loc[self.feature_stats_['names'].isin(to_drop_cols), 'step'] = n\n",
    "            self.feature_stats_.loc[self.feature_stats_['names'].isin(to_drop_cols), 'train_scores'] = \\\n",
    "                self.grid_train_scores_[0]\n",
    "            self.feature_stats_.loc[self.feature_stats_['names'].isin(to_drop_cols), 'test_scores'] = \\\n",
    "                self.grid_test_scores_[0]\n",
    "            self.feature_stats_.loc[self.feature_stats_['names'].isin(to_drop_cols), 'train_sd'] = self.grid_train_sd_[\n",
    "                0]\n",
    "            self.feature_stats_.loc[self.feature_stats_['names'].isin(to_drop_cols), 'test_sd'] = self.grid_test_sd_[0]\n",
    "\n",
    "            if verbose >= 1:\n",
    "                print(f'Test score {self.grid_test_scores_[0]:.4f} with sd {self.grid_test_sd_[0]:.4f}')\n",
    "\n",
    "        self.feature_stats_['step'] -= self.feature_stats_['step'].min() - 1\n",
    "        best_step = self._threshold_select_best_step(threshold)\n",
    "        features = self.feature_stats_[self.feature_stats_[\"step\"] <= best_step]['names'].tolist()\n",
    "        self.stats_ = {\n",
    "            'score': self.score,\n",
    "            'n_features': len(features),\n",
    "            'step': best_step,\n",
    "        }\n",
    "        self.feature_stats_['support'] = np.where(self.feature_stats_['step'] <= best_step, True, False)\n",
    "        self.support_ = np.asarray(self.feature_stats_['support'].tolist())\n",
    "\n",
    "    def transform(self, data, threshold=0, max_features=0, min_features=0):\n",
    "        self.threshold = threshold\n",
    "        best_step = self._threshold_select_best_step(self.threshold)\n",
    "        features = self.feature_stats_[self.feature_stats_[\"step\"] <= best_step]['names'].tolist()\n",
    "        self.stats_ = {\n",
    "            'score': self.score,\n",
    "            'n_features': len(features),\n",
    "            'step': best_step,\n",
    "        }\n",
    "        self.feature_stats_['support'] = np.where(self.feature_stats_['step'] <= best_step, True, False)\n",
    "        self.support_ = np.asarray(self.feature_stats_['support'].tolist())\n",
    "        return data.iloc[:, self.support_]\n",
    "\n",
    "    def plot(self, path=None):\n",
    "\n",
    "        x = np.cumsum(self.feature_stats_.groupby('step').count()['names'].tolist())\n",
    "        y1 = np.array(self.grid_train_scores_)\n",
    "        y2 = np.array(self.grid_test_scores_)\n",
    "        sd1 = np.array(self.grid_train_sd_)\n",
    "        sd2 = np.array(self.grid_test_sd_)\n",
    "        y_min = np.min(y2 - sd2) - 0.01\n",
    "        y_max = np.max(y2 + sd2) + 0.01\n",
    "\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "        # Plot the data, set the linewidth, color and transparency of the\n",
    "        # line, provide a label for the legend\n",
    "        # ax.plot(x, y1, lw = 1, color = '#539caf', alpha = 1, label = 'train')\n",
    "        ax.plot(x, y2, lw=2, alpha=1,\n",
    "                label=f\"n_features={self.stats_['n_features']}\\nscore={self.stats_['score']:.4f}\")\n",
    "\n",
    "        # Shade the confidence interval\n",
    "        # ax.fill_between(x, y1+2*sd1, y1-2*sd1, color = '#539caf', alpha = 0.4)\n",
    "        ax.fill_between(x, y2 + 2 * sd2, y2 - 2 * sd2, alpha=0.4)\n",
    "        # Label the axes and provide a title\n",
    "        ax.set_title('Number of features vs. cross-validation scores')\n",
    "        ax.set_xlabel(f\"Number of features\")\n",
    "        ax.set_ylabel(\"Cross validation score (roc auc)\")\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        # ax.set_xlim([1,200])\n",
    "        # Display legend\n",
    "        ax.legend(loc='best')\n",
    "        ax.vlines(self.stats_['n_features'], 0, 1, color='grey', lw=1, linestyle='--')\n",
    "        fig = ax.get_figure()\n",
    "        if path: fig.savefig(path)\n",
    "from rfecv import RFECV\n",
    "\n",
    "\n",
    "rfecv_obj = RFECV(estimator = lgb.LGBMClassifier(n_jobs=25, random_state=SEED), \n",
    "                  step=1, cv=3, verbose=2,\n",
    "                  scoring='roc_auc')\n",
    "rfecv_obj.fit(df_feat_sel.drop(columns=['target']), df_feat_sel['target'])\n",
    "\n",
    "feats = set(rfecv_obj.feature_stats_[rfecv_obj.feature_stats_.support == True].names.tolist())\n",
    "feats = list(feats)\n",
    "\n",
    "print('features after RFECV FS..., featshape = ', len(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "def get_default_spark_session_ld3(spark_version=2):\n",
    "    os.environ['SPARK_MAJOR_VERSION'] = str(spark_version)\n",
    "    os.environ['SPARK_HOME'] = f'/usr/sdp/current/spark{spark_version}-client/'\n",
    "    python_path = sys.executable\n",
    "    os.environ['PYSPARK_DRIVER'] = python_path\n",
    "    os.environ['PYSPARK_PYTHON'] = python_path\n",
    "    os.environ['PYSPARK_DRIVER_PYTHON'] = python_path\n",
    "    os.environ['LD_LIBRARY_PATH'] = '/opt/python/virtualenv/jupyter/lib'\n",
    "    sys.path.insert(0, f'/usr/sdp/current/spark{spark_version}-client/python/')\n",
    "    sys.path.insert(0, f'/usr/sdp/current/spark{spark_version}-client/py4j-0.10.9.3-src.zip')\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = (\n",
    "        SparkSession\n",
    "            .builder\n",
    "            .master(\"yarn\")\n",
    "            .appName('Andrew_Availibility_SP')\n",
    "            .config(\"spark.ui.enabled\", \"true\")       \n",
    "    .config('spark.executor.cores', '8')\\\n",
    "    .config('spark.executor.memory', '64g')\\\n",
    "    .config('spark.executor.memoryOverhead', '1g')\\\n",
    "    .config('spark.driver.memory', '12g')\\\n",
    "    .config('spark.driver.maxResultSize', '16g')\\\n",
    "    .config('spark.shuffle.service.enabled', 'true')\\\n",
    "    .config('spark.hadoop.mapreduce.input.fileinputformat.input.dir.recursive', 'true')\\\n",
    "    .config('spark.dynamicAllocation.enabled', 'true')\\\n",
    "    .config('spark.dynamicAllocation.executorIdleTimeout', '120s')\\\n",
    "    .config('spark.dynamicAllocation.cachedExecutorIdleTimeout', '600s')\\\n",
    "    .config('spark.dynamicAllocation.initialExecutors', '3')\\\n",
    "    .config('spark.dynamicAllocation.maxExecutors', '12')\\\n",
    "    .config('spark.port.maxRetries', '150')\\\n",
    "    .config('spark.sql.hive.manageFilesourcePartitions', 'false')\\\n",
    "    .config('spark.sql.execution.arrow.pyspark.enabled', 'true')\\\n",
    "    .config('spark.sql.parquet.writeLegacyFormat', 'true')\\\n",
    "    .config('spark.sql.legacy.parquet.datetimeRebaseModelInRead','LEGACY')\\\n",
    "    .config('spark.sql.parquet.int96RebaseModeInWrite','LEGACY')\\\n",
    "    .config('spark.sql.parquet.int96RebaseModeInRead', 'CORRECTED')\n",
    "            .getOrCreate()\n",
    "    )\n",
    "    return spark\n",
    "\n",
    "hc = get_default_spark_session_ld3(3)\n",
    "oos_finally = hc.sql(\"\"\"\n",
    "      select *\n",
    "      from  arnsdpsbx_t_team_bsp.data_model_242355 \"\"\").toPandas()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8_dmlmpack121_1.2.1",
   "language": "python",
   "name": "dmlmpack121"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
